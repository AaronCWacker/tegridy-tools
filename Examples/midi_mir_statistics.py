# -*- coding: utf-8 -*-
"""MIDI_MIR_Statistics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VfVMRrrJY_1BFy8gLCOYpAKJZm-FcKcu

# MIDI MIR Statistics Notebook (ver 1.0)

***

## View detailed info and stats for the specified MIDI file

***

#### Project Los Angeles
#### Tegridy Code 2021
"""

# Commented out IPython magic to ensure Python compatibility.
#@title Install all dependencies
!pip install mido
!git clone https://github.com/sniperwrb/python-midi
!apt-get install swig
# %cd /content/python-midi
!python setup.py install
# %cd /content/
!mkdir /content/midis/

#@title Import needed modules
import os
import numpy as np
import mido
import string
import matplotlib.pyplot as plt

import sys, math, time

import midi

from mido import MidiFile
from operator import itemgetter

#@title Default title text
MIDI_file_to_analyze = "/content/seed.mid" #@param {type:"string"}

#@title MIDI Stats 1

# https://github.com/LiuFang816/SALSTM_py_data/blob/d494b3041069d377d6a7a9c296a14334f2fa5acc/python/olofmogren_c-rnn-gan/c-rnn-gan-master/midi_statistics.py
# https://github.com/gbramleysimmons/musictransformers

def msg2dict(msg):
    result = dict()
    if 'note_on' in msg:
        on_ = True
    elif 'note_off' in msg:
        on_ = False
    else:
        on_ = None
    result['time'] = int(msg[msg.rfind('time'):].split(' ')[0].split('=')[1].translate(
        str.maketrans({a: None for a in string.punctuation})))

    if on_ is not None:
        for k in ['note', 'velocity']:
            result[k] = int(msg[msg.rfind(k):].split(' ')[0].split('=')[1].translate(
                str.maketrans({a: None for a in string.punctuation})))
    return [result, on_]


def switch_note(last_state, note, velocity, on_=True):
    # piano has 88 notes, corresponding to note id 21 to 108, any note out of this range will be ignored
    result = [0] * 88 if last_state is None else last_state.copy()
    if 21 <= note <= 108:
        result[note-21] = velocity if on_ else 0
    return result


def get_new_state(new_msg, last_state):
    new_msg, on_ = msg2dict(str(new_msg))
    new_state = switch_note(last_state, note=new_msg['note'], velocity=new_msg['velocity'], on_=on_) if on_ is not None else last_state
    return [new_state, new_msg['time']]


def track2seq(track):
    # piano has 88 notes, corresponding to note id 21 to 108, any note out of the id range will be ignored
    result = []
    last_state, last_time = get_new_state(str(track[0]), [0]*88)
    for i in range(1, len(track)):
        new_state, new_time = get_new_state(track[i], last_state)
        if new_time > 0:
            result += [last_state]*new_time
        last_state, last_time = new_state, new_time
    return result


def mid2arry(mid, min_msg_pct=0.1):
    tracks_len = [len(tr) for tr in mid.tracks]
    min_n_msg = max(tracks_len) * min_msg_pct
    # convert each track to nested list
    all_arys = []
    for i in range(len(mid.tracks)):
        if len(mid.tracks[i]) > min_n_msg:
            ary_i = track2seq(mid.tracks[i])
            all_arys.append(ary_i)
    # make all nested list the same length
    max_len = max([len(ary) for ary in all_arys])
    for i in range(len(all_arys)):
        if len(all_arys[i]) < max_len:
            all_arys[i] += [[0] * 88] * (max_len - len(all_arys[i]))
    all_arys = np.array(all_arys)
    all_arys = all_arys.max(axis=0)
    # trim: remove consecutive 0s in the beginning and at the end
    sums = all_arys.sum(axis=1)
    ends = np.where(sums > 0)[0]
    return all_arys[min(ends): max(ends)]


def print_array(midi_array):
    
    plt.plot(range(midi_array.shape[0]), np.multiply(np.where(midi_array > 0, 1, 0), range(1, 89)), marker='.',
             markersize=1, linestyle='')
    #plt.show()
    plt.savefig('MIDI Stats Graph.png', dpi=300)


def main():
    # Need to change filepath to midi path
    filepath = MIDI_file_to_analyze
    midi_file = mido.MidiFile(filepath, clip=True)
    midi_array = mid2arry(midi_file)
    print_array(midi_array)


if __name__ == '__main__':
    main()

#@title MIDI Stats 2
# Tools to load and save midi files for the rnn-gan-project.
# https://github.com/LiuFang816/SALSTM_py_data/blob/d494b3041069d377d6a7a9c296a14334f2fa5acc/python/olofmogren_c-rnn-gan/c-rnn-gan-master/midi_statistics.py
# 
# https://github.com/TimStroup/Classical-Music-Generator/blob/847a410acb7e993c33e2116af45a7ccdb6b1a9e9/midi_statistics.py
#
# Written by Olof Mogren, http://mogren.one/
#
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================


GENRE      = 0
COMPOSER   = 1
SONG_DATA  = 2

# INDICES IN BATCHES:
LENGTH     = 0
FREQ       = 1
VELOCITY   = 2
TICKS_FROM_PREV_START      = 3

# INDICES IN SONG DATA (NOT YET BATCHED):
BEGIN_TICK = 3
CHANNEL    = 4

debug = ''
#debug = 'overfit'


base_tones = {'C':   0,
              'C#':  1, 
              'D':   2,
              'D#':  3,
              'E':   4,
              'F':   5,
              'F#':  6,
              'G':   7,
              'G#':  8,
              'A':   9,
              'A#': 10,
              'B':  11}

scale = {}
#Major scale:
scale['major'] = [0,2,4,5,7,9,11]
#(W-W-H-W-W-W-H)
#(2 2 1 2 2 2 1)

#Natural minor scale:
scale['natural_minor'] = [0,2,3,5,7,8,10]
#(W-H-W-W-H-W-W)
#(2 1 2 2 1 2 2)
 
#Harmonic minor scale:
scale['harmonic_minor'] = [0,2,3,5,7,8,11]
#(W-H-W-W-H-WH-H)
#(2 1 2 2 1 3 1)

tone_names = {}
for tone_name in base_tones:
  tone_names[base_tones[tone_name]] = tone_name


def get_tones(midi_pattern):
  """
  returns a dict of statistics, keys: [scale_distribution,
  """
  
  tones = []
  
  for track in midi_pattern:
    for event in track:
      if type(event) == midi.events.SetTempoEvent:
        pass # These are currently ignored
      elif (type(event) == midi.events.NoteOffEvent) or \
           (type(event) == midi.events.NoteOnEvent and \
            event.velocity == 0):
        pass # not needed here
      elif type(event) == midi.events.NoteOnEvent:
        tones.append(event.data[0])
  return tones 

def detect_beat(midi_pattern):
  """
  returns a dict of statistics, keys: [scale_distribution,
  """
  
  abs_ticks = []
  
  # Tempo:
  ticks_per_quarter_note = float(midi_pattern.resolution)
  
  for track in midi_pattern:
    abs_tick=0
    for event in track:
      abs_tick += event.tick
      if type(event) == midi.events.SetTempoEvent:
        pass # These are currently ignored
      elif (type(event) == midi.events.NoteOffEvent) or \
           (type(event) == midi.events.NoteOnEvent and \
            event.velocity == 0):
        pass
      elif type(event) == midi.events.NoteOnEvent:
        abs_ticks.append(abs_tick)
  stats = {}
  for quarter_note_estimate in range(int(ticks_per_quarter_note), int(0.75*ticks_per_quarter_note), -1):
    #print('est: {}'.format(quarter_note_estimate))
    avg_ticks_off = []
    for begin_tick in range(quarter_note_estimate):
      ticks_off = []
      for abs_tick in abs_ticks:
        #print('abs_tick: {} % {}'.format(abs_tick, quarter_note_estimate/4))
        sixteenth_note_estimate = quarter_note_estimate/4
        ticks_off_sixteenths = int((begin_tick+abs_tick)%sixteenth_note_estimate)
        if ticks_off_sixteenths > sixteenth_note_estimate/2:
          # off, but before beat 
          ticks_off_sixteenths = -(ticks_off_sixteenths-sixteenth_note_estimate)
        #print('ticks_off: {}'.format(ticks_off_sixteenths))
        ticks_off.append(ticks_off_sixteenths)
      avg_ticks_off.append(float(sum(ticks_off))/float(len(ticks_off)))
      #print('avg_ticks_off: {}. min: {}.'.format(avg_ticks_off, min(avg_ticks_off)))
    stats[quarter_note_estimate] = min(avg_ticks_off)
  return stats

def get_abs_ticks(midi_pattern):
  abs_ticks = []
  for track in midi_pattern:
    abs_tick=0
    for event in track:
      abs_tick += event.tick
      if type(event) == midi.events.SetTempoEvent:
        pass # These are currently ignored
      elif (type(event) == midi.events.NoteOffEvent) or \
           (type(event) == midi.events.NoteOnEvent and \
            event.velocity == 0):
        pass
      elif type(event) == midi.events.NoteOnEvent:
        abs_ticks.append(abs_tick)
  abs_ticks.sort()
  return abs_ticks

def get_top_k_intervals(midi_pattern, k):
  """
  returns a fraction of the noteon events in midi_pattern that are polyphonous
  (several notes occurring at the same time).
  Here, two note on events are counted as the same event if they
  occur at the same time, and in this case it is considered a polyphonous event.
  """
  intervals = {}
  abs_ticks = get_abs_ticks(midi_pattern)
  accumulator = 0
  last_abs_tick = 0
  for abs_tick in abs_ticks:
    interval = abs_tick-last_abs_tick
    if interval not in intervals:
      intervals[interval] = 0
    intervals[interval] += 1
    accumulator += 1
    last_abs_tick = abs_tick
  intervals_list = [(interval, intervals[interval]/float(accumulator)) for interval in intervals]
  intervals_list.sort(key=lambda i: i[1], reverse=True)
  return intervals_list[:k]


def get_polyphony_score(midi_pattern):
  """
  returns a fraction of the noteon events in midi_pattern that are polyphonous
  (several notes occurring at the same time).
  Here, two note on events are counted as the same event if they
  occur at the same time, and in this case it is considered a polyphonous event.
  """
  
  abs_ticks = get_abs_ticks(midi_pattern)
  monophonous_events = 0
  polyphonous_events = 0
  
  last_abs_tick = 0
  tones_in_current_event = 0
  for abs_tick in abs_ticks:
    if abs_tick == last_abs_tick:
      tones_in_current_event += 1
    else:
      if tones_in_current_event == 1:
        monophonous_events += 1
      elif tones_in_current_event > 1:
        polyphonous_events += 1
      tones_in_current_event = 1
    last_abs_tick = abs_tick
    if tones_in_current_event == 1:
      monophonous_events += 1
    elif tones_in_current_event > 1:
      polyphonous_events += 1
  if polyphonous_events == 0:
    return 0.0
  return float(polyphonous_events)/(polyphonous_events+monophonous_events)


def get_rhythm_stats(midi_pattern):
  """
  returns a dict of statistics, keys: [scale_distribution,
  """
  
  abs_ticks = []
  
  # Tempo:
  ticks_per_quarter_note = float(midi_pattern.resolution)
  
  # Multiply with output_ticks_pr_input_tick for output ticks.
  for track in midi_pattern:
    abs_tick=0
    for event in track:
      abs_tick += event.tick
      if type(event) == midi.events.SetTempoEvent:
        pass # These are currently ignored
      elif (type(event) == midi.events.NoteOffEvent) or \
           (type(event) == midi.events.NoteOnEvent and \
            event.velocity == 0):
        pass
      elif type(event) == midi.events.NoteOnEvent:
        abs_ticks.append(abs_tick)
  stats = {}
  for abs_tick in abs_ticks:
    ticks_since_quarter_note = int(abs_tick%ticks_per_quarter_note)
    if ticks_since_quarter_note not in stats:
      stats[ticks_since_quarter_note] = 1
    else:
      stats[ticks_since_quarter_note] += 1
  return stats


def get_intensities(midi_pattern):
  """
  returns a dict of statistics, keys: [scale_distribution,
  """
  
  intensities = []
  
  for track in midi_pattern:
    abs_tick=0
    for event in track:
      abs_tick += event.tick
      if type(event) == midi.events.SetTempoEvent:
        pass # These are currently ignored
      elif (type(event) == midi.events.NoteOffEvent) or \
           (type(event) == midi.events.NoteOnEvent and \
            event.velocity == 0):
        pass
      elif type(event) == midi.events.NoteOnEvent:
        intensities.append(event.velocity)
  return (min(intensities), max(intensities))


def get_midi_pattern(filename):
  try:
    return midi.read_midifile(filename)
  except:
    print ('Error reading {}'.format(filename))
    return None

def tones_to_scales(tones):
  """
   Midi to tone name (octave: -5):
   0: C
   1: C#
   2: D
   3: D#
   4: E
   5: F
   6: F#
   7: G
   8: G#
   9: A
   10: A#
   11: B
   Melodic minor scale is ignored.
   One octave is 12 tones.
  """
  counts = {}
  for base_tone in base_tones:
    counts[base_tone] = {}
    counts[base_tone]['major'] = 0
    counts[base_tone]['natural_minor'] = 0
    counts[base_tone]['harmonic_minor'] = 0

  if not len(tones):
    frequencies = {}
    for base_tone in base_tones:
      frequencies[base_tone] = {}
      for scale_label in scale:
        frequencies[base_tone][scale_label] = 0.0
    return frequencies
  for tone in tones:
    for base_tone in base_tones:
      for scale_label in scale:
        if tone%12-base_tones[base_tone] in scale[scale_label]:
          counts[base_tone][scale_label] += 1
  frequencies = {}
  for base_tone in counts:
    frequencies[base_tone] = {}
    for scale_label in counts[base_tone]:
      frequencies[base_tone][scale_label] = float(counts[base_tone][scale_label])/float(len(tones))
  return frequencies

def repetitions(tones):
  rs = {}
  #print(tones)
  #print(len(tones)/2)
  for l in range(2, min(len(tones)/2, 10)):
    #print (l)
    rs[l] = 0
    for i in range(len(tones)-l*2):
      for j in range(i+l,len(tones)-l):
        #print('comparing \'{}\' and \'{}\''.format(tones[i:i+l], tones[j:j+l]))
        if tones[i:i+l] == tones[j:j+l]:
          rs[l] += 1
  rs2 = {}
  for r in rs:
    if rs[r]:
      rs2[r] = rs[r]
  return rs2
      

def tone_to_tone_name(tone):
  """
   Midi to tone name (octave: -5):
   0: C
   1: C#
   2: D
   3: D#
   4: E
   5: F
   6: F#
   7: G
   8: G#
   9: A
   10: A#
   11: B
   One octave is 12 tones.
  """

  base_tone = tone_names[tone%12]
  octave = tone/12-5
  return '{} {}'.format(base_tone, octave)

def max_likelihood_scale(tones):
  scale_statistics = tones_to_scales(tones) 
  stat_list = []
  for base_tone in scale_statistics:
    for scale_label in scale_statistics[base_tone]:
      stat_list.append((base_tone, scale_label, scale_statistics[base_tone][scale_label]))
  stat_list.sort(key=lambda e: e[2], reverse=True)
  return (stat_list[0][0]+' '+stat_list[0][1], stat_list[0][2])

def tone_to_freq(tone):
  """
    returns the frequency of a tone. 
    formulas from
      * https://en.wikipedia.org/wiki/MIDI_Tuning_Standard
      * https://en.wikipedia.org/wiki/Cent_(music)
  """
  return math.pow(2, ((float(tone)-69.0)/12.0)) * 440.0

def freq_to_tone(freq):
  """
    returns a dict d where
    d['tone'] is the base tone in midi standard
    d['cents'] is the cents to make the tone into the exact-ish frequency provided.
               multiply this with 8192 to get the midi pitch level.
    formulas from
      * https://en.wikipedia.org/wiki/MIDI_Tuning_Standard
      * https://en.wikipedia.org/wiki/Cent_(music)
  """
  if freq == 0.0:
    return None
  float_tone = (69.0+12*math.log(float(freq)/440.0, 2))
  int_tone = int(float_tone)
  cents = int(1200*math.log(float(freq)/tone_to_freq(int_tone), 2))
  return {'tone': int_tone, 'cents': cents}

def cents_to_pitchwheel_units(cents):
  return int(40.96*(float(cents)))

def get_all_stats(midi_pattern):
  stats = {}
  if not midi_pattern:
    print('Failed to read midi pattern.')
    return None
  tones = get_tones(midi_pattern)
  if len(tones) == 0:
    print('This is an empty song.')
    return None
  stats['num_tones'] = len(tones)
  stats['tone_min'] = min(tones)
  stats['freq_min'] = tone_to_freq(min(tones))
  stats['tone_max'] = max(tones)
  stats['freq_max'] = tone_to_freq(max(tones))
  stats['tone_span'] = max(tones)-min(tones)
  stats['freq_span'] = tone_to_freq(max(tones))-tone_to_freq(min(tones))
  stats['tones_unique'] = len(set(tones))
  rs = repetitions(tones)
  for r in range(2,10):
    if r in rs:
      stats['repetitions_{}'.format(r)] = rs[r]
    else:
      stats['repetitions_{}'.format(r)] = 0
  
  ml = max_likelihood_scale(tones)
  stats['scale'] = ml[0]
  stats['scale_score'] = ml[1]
  
  beat_stats = detect_beat(midi_pattern)
  minval = float(midi_pattern.resolution)
  argmin = -1
  for beat in beat_stats:
    #print('Looking at beat: {}. Avg ticks off: {}.'.format(beat, beat_stats[beat]))
    if beat_stats[beat] < minval:
      minval = beat_stats[beat]
      argmin = beat
  stats['estimated_beat'] = argmin
  stats['estimated_beat_avg_ticks_off'] = minval
  (min_int, max_int) = get_intensities(midi_pattern)
  stats['intensity_min'] = min_int
  stats['intensity_max'] = max_int
  stats['intensity_span'] = max_int-min_int

  stats['polyphony_score'] = get_polyphony_score(midi_pattern)
  stats['top_10_intervals'] = get_top_k_intervals(midi_pattern, 10)
  stats['top_2_interval_difference'] = 0.0
  if len(stats['top_10_intervals']) > 1:
    stats['top_2_interval_difference'] = abs(stats['top_10_intervals'][1][0]-stats['top_10_intervals'][0][0])
  stats['top_3_interval_difference'] = 0.0
  if len(stats['top_10_intervals']) > 2:
    stats['top_3_interval_difference'] = abs(stats['top_10_intervals'][2][0]-stats['top_10_intervals'][0][0])

  return stats

def get_gnuplot_line(midi_patterns, i, showheader=True):
  stats = []
  print('#getting stats...')
  stats_time = time.time()
  for p in midi_patterns:
    stats.append(get_all_stats(p))
  print('done. time: {}'.format(time.time()-stats_time))
  #print(stats)
  stats_keys_string = ['scale']
  stats_keys = ['scale_score', 'tone_min', 'tone_max', 'tone_span', 'freq_min', 'freq_max', 'freq_span', 'tones_unique', 'repetitions_2', 'repetitions_3', 'repetitions_4', 'repetitions_5', 'repetitions_6', 'repetitions_7', 'repetitions_8', 'repetitions_9', 'estimated_beat', 'estimated_beat_avg_ticks_off', 'intensity_min', 'intensity_max', 'intensity_span', 'polyphony_score', 'top_2_interval_difference', 'top_3_interval_difference', 'num_tones']
  gnuplotline = ''
  if showheader:
    gnuplotline = '# global-step {} {}\n'.format(' '.join([s.replace(' ', '_') for s in stats_keys_string]), ' '.join(stats_keys))
  gnuplotline += '{} {} {}\n'.format(i, ' '.join(['{}'.format(stats[0][key].replace(' ', '_')) for key in stats_keys_string]), ' '.join(['{:.3f}'.format(sum([s[key] for s in stats])/float(len(stats))) for key in stats_keys]))
  return gnuplotline



def main():
  if len(sys.argv) > 2 and sys.argv[1] == '--gnuplot':
    #number = sys.argv[2]
    patterns = []
    for i in range(3,len(sys.argv)):
      #print(i)
      filename = sys.argv[i]
      print('#File: {}'.format(filename))
      #patterns.append(get_midi_pattern(filename))
      print(get_gnuplot_line([get_midi_pattern(filename)], i, showheader=(i==0)))
    
  else:
    for i in range(1,len(sys.argv)):
      #filename = sys.argv[i]
      filename = MIDI_file_to_analyze
      print('File: {}'.format(filename))
      midi_pattern = get_midi_pattern(filename)
      stats = get_all_stats(midi_pattern)
      if stats is None:
        print('Could not extract stats.')
      else:
        print ('ML scale estimate: {}: {:.2f}'.format(stats['scale'], stats['scale_score']))
        print ('Min tone: {}, {:.1f} Hz.'.format(tone_to_tone_name(stats['tone_min']), stats['freq_min']))
        print ('Max tone: {}, {:.1f} Hz.'.format(tone_to_tone_name(stats['tone_max']), stats['freq_max']))
        print ('Span: {} tones, {:.1f} Hz.'.format(stats['tone_span'], stats['freq_span']))
        print ('Unique tones: {}'.format(stats['tones_unique']))
        for r in range(2,10):
          print('Repetitions of len {}: {}'.format(r, stats['repetitions_{}'.format(r)]))
        print('Estimated beat: {}. Avg ticks off: {:.2f}.'.format(stats['estimated_beat'], stats['estimated_beat_avg_ticks_off']))
        print('Intensity: min: {}, max: {}.'.format(stats['intensity_min'], stats['intensity_max']))
        print('Polyphonous events: {:.2f}.'.format(stats['polyphony_score']))
        print('Top intervals:')
        for interval,score in stats['top_10_intervals']:
          print('{}: {:.2f}.'.format(interval,score))
        print('Top 2 interval difference: {}.'.format(stats['top_2_interval_difference']))
        print('Top 3 interval difference: {}.'.format(stats['top_3_interval_difference']))


if __name__ == "__main__":
  main()

#@title MIDI Stats 3
# https://github.com/mbereket/music-transcription

# Comverts MIDI file pattern to representation of notes events in absolute time
class NoteEvents:
    def __init__(self, pattern, note_tracks=None, start_on_note=True):
        self._event_list = []
        self.note_time_list = []
        pattern.make_ticks_abs()
        self.pattern = pattern
        self.ticks_per_beat = pattern.resolution
        self.numNotes = 88
        # offset between note index and MIDI note number
        self.noteOffset = 9
        # list of track names to include notes from
        self.note_tracks = note_tracks
        self.names = self._name_tracks()
        self.start_on_note = start_on_note
        self._parse_events()

    def _name_tracks(self):
        names = [None] * len(self.pattern)
        for i in range(len(self.pattern)):
            for event in self.pattern[i]:
                if type(event) == midi.events.TrackNameEvent:
                    names[i] = event.text
                break
        return names

    def _parse_events(self):
        for i in range(len(self.pattern)):
            for event in self.pattern[i]:
                if type(event) in (midi.events.NoteOnEvent, midi.events.NoteOffEvent):
                    if self.note_tracks == None or self.names[i] in self.note_tracks:
                        self._event_list.append(event)
                elif type(event) == midi.events.SetTempoEvent:
                    self._event_list.append(event)
                elif type(event) == midi.events.EndOfTrackEvent and event.tick != 0:
                    self._event_list.append(event)
        self._event_list = sorted(self._event_list, key=lambda x: x.tick)
        self._event_list_timed()


    def _event_list_timed(self):
        assert(type(self._event_list[0]) == midi.events.SetTempoEvent)
        microseconds_per_beat = self._event_list[0].get_mpqn()
        prev_time = 0
        prev_tick = 0
        microseconds_per_tick = float(microseconds_per_beat) / self.ticks_per_beat
        for event in self._event_list:
            tick_diff = event.tick - prev_tick
            curr_time = prev_time + (tick_diff * microseconds_per_tick)
            if type(event) != midi.events.SetTempoEvent:
                self.note_time_list.append((event, curr_time))
                prev_time = curr_time
                prev_tick = event.tick
            else:
                prev_time = curr_time
                prev_tick = event.tick
                microseconds_per_beat = event.get_mpqn()
                microseconds_per_tick = float(microseconds_per_beat) / self.ticks_per_beat
        start_time = self.note_time_list[0][1]

        if self.start_on_note:
            for i, tup in enumerate(self.note_time_list):
                self.note_time_list[i] = (tup[0],tup[1]-start_time)
        self._last_event_time = self.note_time_list[-1][1]

    def _note_off(self, note_event):
        return ((type(note_event) == midi.events.NoteOnEvent) and (note_event.get_velocity() == 0)) \
                    or type(note_event) == midi.events.NoteOffEvent

    # returns index of first slice at or after given time
    # time in microseconds
    def time_to_slice(self, t, slices_per_second):
        microseconds_per_slice = 1e6 / slices_per_second
        return np.ceil(float(t) / microseconds_per_slice).astype(int)

    # duration in seconds
    def get_ground_truth(self, slices_per_second, duration=None):
        microseconds_per_slice = 1e6 / slices_per_second
        number_slices = np.ceil(self._last_event_time / microseconds_per_slice).astype(int)
        ground_truth = np.zeros(self.numNotes * number_slices).reshape(self.numNotes, number_slices)
        template = np.zeros(self.numNotes).reshape(self.numNotes,1)
        prev_time = 0
        for note, curr_time in self.note_time_list:
            if prev_time != curr_time:
                prev_time_slice = self.time_to_slice(prev_time, slices_per_second)
                curr_time_slice = self.time_to_slice(curr_time, slices_per_second)
                #make all slices in [prev_time, curr_time) equal to current template
                ground_truth[:,prev_time_slice:curr_time_slice] = template.repeat(curr_time_slice - prev_time_slice, axis=1)
            if type(note) == midi.events.EndOfTrackEvent:
                break
            pitch_index = note.get_pitch() - self.noteOffset
            if pitch_index >= 0 and pitch_index < self.numNotes:
                if self._note_off(note):
                    template[pitch_index] = 0
                else:
                    template[pitch_index] = 1
            prev_time = curr_time
        if duration != None:
            ground_truth = ground_truth[:,:self.time_to_slice(1e6 * duration, slices_per_second)]
        return ground_truth



if __name__ == '__main__':
    pattern = midi.read_midifile(MIDI_file_to_analyze)
    events = NoteEvents(pattern)
    truth = events.get_ground_truth(31.25, 15)
    plt.matshow(truth)
    plt.show()

#@title MIDI Stats 4
# https://github.com/Astner/exjobb/blob/1abc750a7a4d9af52e273ef24c2c32d0e431e1a6/concepts-master/experimental/higherorder/formats/midi/miditocontext/midiutils.py
# 

# Copyright 2015 Daniel Gillblad (dgi@sics.se).

# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

# http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Selecte active channels
# Here, all channels except 10 are used, as this MIDI channel is used for percussion only
# in General MIDI files (note that we index channels from 0, not 1)
activeChannels = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15)

# Time during which events are considered simultaneous
simTimeLimit = 50

# Fraction of time notes need to be overlapping to be considered played together
overlapFracLimit = 0.95

# Print info on specified MIDI file
def printMidiFileInfo(midifile):
	mid = MidiFile(midifile)
	print("File:", os.path.basename(midifile),
	      "Type:", mid.type,
	      "Length: ",
	      end = "")
	if mid.type < 2:
		print(mid.length)
	else:
		print("N/A")

# Print messages in MIDI file
def printMidiMessages(midifile):
	mid = MidiFile(midifile)
	for i, track in enumerate(mid.tracks):
		print('Track {}: {}'.format(i, track.name))
		for message in track:
			print(message)

# Simple class for representing current note state,
# given a series of messages given in order to the update method.
class NoteState:
	nstate = [-1] * 128

	def printState(self):
		print('|', end = '')
		for i in self.nstate[22:116]:
			if i >= 0:
				print('*', end = '')
			else:
				print('-', end = '')
		print('|')

	def update(self, message, time = 0):
		if message.type == 'all_notes_off':
			self.nstate = [-1] * 128
		elif message.type == 'note_off' or (message.type == 'note_on' and message.velocity <= 0):
			rmsg = [(self.nstate[message.note], time, message.note)]
			self.nstate[message.note] = -1
			return rmsg
		elif message.type == 'note_on':
			self.nstate[message.note] = time
			return []
		return []

# Determines if a message is a "note" message: note on, note off, or all notes off
def isNoteMessage(msg):
	if msg.type == 'note_on' or msg.type == 'note_off' or msg.type == 'all_notes_off':
		return True
	else:
		return False

# Determines if a message is a "note" message on a specific channel
def isNoteMessageOnChannel(msg, ch):
	if isNoteMessage(msg) and msg.channel == ch:
		return True
	else:
		return False

# Convert a MIDI file to a list of note events, each note given by
# (start-time, end-time, note number). Returns a nested list with
# one list per channel per track.
def fileToNoteList(midifile):
	mid = MidiFile(midifile)
	allnotes = []
	for i, track in enumerate(mid.tracks):
		tracknotes = []
		for channel in activeChannels:
			channelnotes = []
			state = NoteState()
			cTime = 0
			for message in track:
				cTime += message.time
				if isNoteMessageOnChannel(message, channel):
					channelnotes += state.update(message, cTime)
			if len(channelnotes) >= 1:
				tracknotes += [sorted(channelnotes, key=itemgetter(0,1))]
		if len(tracknotes) >= 1:
			allnotes += [tracknotes]
	return allnotes

# Convert a note list to a list of notes played together.
def playedTogether(notelist):
	together = []
	for i, note in enumerate(notelist):
		# Find overlaps
		for fnote in notelist[i + 1:]:
			if fnote[0] > note[1]:
				break
			overlap_a = (note[1] - fnote[0]) / (note[1] - note[0])
			overlap_b = (fnote[1] - note[1]) / (fnote[1] - fnote[0])
			if overlap_a >= overlapFracLimit or overlap_b >= overlapFracLimit:
				together += [[note[2], fnote[2]]]
	return together

# Find all notes played together in midifile, separated by track and channel
def allNotesPlayedTogether(midifile):
	notelists = fileToNoteList(midifile)
	alltogether = []
	for t in notelists:
		for c in t:
			alltogether += playedTogether(c)
	return alltogether

# Print a graphic representation of all note messages in a MIDI file
# on a (reasonable) easy to read format.
def printNoteMessages(midifile):
	mid = MidiFile(midifile)
	for i, track in enumerate(mid.tracks):
		print('Track {}: {}'.format(i, track.name))
		for channel in activeChannels:
			print('Channel:', channel)
			state = NoteState()
			cTime = 0
			simTime = 0
			for message in track:
				cTime += message.time
				if isNoteMessageOnChannel(message, channel):
					# If message is outside what would be considered simultaneous,
					# emit last state and reset simultaneous time counter
					if (simTime + message.time) >= simTimeLimit:
						print(cTime, end = '')
						state.printState()
						simTime = 0
					else:
						simTime += message.time
					state.update(message, cTime)

# Print a graphic representation of all note messages in a MIDI file
# on a (reasonable) easy to read format, grouping near simultaneous note events
# for readability.
def printGroupedNoteOnMessages(midifile):
	mid = MidiFile(midifile)
	for i, track in enumerate(mid.tracks):
		print('Track {}: {}'.format(i, track.name))
		for channel in activeChannels:
			print('Channel:', channel)
			cTime = 0
			gTime = 0
			nSet = set()
			for message in track:
				cTime += message.time
				if message.type == 'note_on' and message.velocity > 0 and message.channel == channel:
					if (cTime - gTime) >= simTimeLimit:
						print(cTime, nSet)
						gTime = cTime
						nSet.clear()
						nSet.add(message.note)
					else:
						nSet.add(message.note)

# Collect a set of statistics for a specified MIDI file object.
def collectMidiNoteStatistics(midifileobj, channel_activity, played_notes, note_offs,
                              running_status, all_notes_off):
	for i, track in enumerate(midifileobj.tracks):
		for channel in activeChannels:
			for message in track:
				if(isNoteMessage(message)):
					channel_activity[message.channel] += 1
					if message.type == 'note_on' and message.velocity > 0:
						played_notes[message.note] += 1
					if message.type == 'note_off':
						note_offs[message.channel] += 1
					if message.type == 'note_on' and message.velocity <= 0:
						running_status[message.channel] += 1
					if message.type == 'all_notes_off':
						all_notes_off[message.channel] += 1

# Print MIDI file statistics compiled for all MIDI files found in the specified directory
# and all sub-directories recursively.
def printMidiFileStatistics(root_dir):
    nr_files = 0
    nr_file_types = [0] * 3
    nr_length_files = 0
    total_length = 0
    channel_activity = [0] * 16
    played_notes = [0] * 127
    note_offs = [0] * 16 # Per channel
    running_status = [0] * 16 # Per channel
    all_notes_off = [0] * 16 # Per channel

    mid = MidiFile(MIDI_file_to_analyze)
    nr_files += 1
    nr_file_types[mid.type] += 1
    if mid.type < 2:
      nr_length_files += 1
      total_length += mid.length
    collectMidiNoteStatistics(mid, channel_activity, played_notes, note_offs,
                              running_status, all_notes_off)

    print('--------------------------------------------------------------------------')
    print('Number of .mid files:', nr_files, '      Type 0:', nr_file_types[0],
          ' Type 1:', nr_file_types[1], ' Type 2:', nr_file_types[2])
    print('Average length:       {:.1f}'.format(total_length / nr_length_files))
    print('--------------------------------------------------------------------------')
    print('Note on messages:    ', sum(played_notes))
    print('Note off messages:   ', sum(note_offs))
    print('Running status off:  ', sum(running_status))
    print('All notes off:       ', sum(all_notes_off))
    print('--------------------------------------------------------------------------')
    print('Channel activity distribution:')
    total_activity = sum(channel_activity)
    for i, act in enumerate(channel_activity):
      if act > 0:
        print('{:2d}: {:.1%} '.format(i + 1, act / total_activity))
    print('--------------------------------------------------------------------------')
    print('Note distribution:')
    total_notes = sum(played_notes)
    for i, nt in enumerate(played_notes):
      if nt > 0:
        print('{:2d}: {:.2%} '.format(i, nt / total_notes))
    print('--------------------------------------------------------------------------')


# Visit files recursively from a root directory.
def visitFilesRecursively(root_dir, extension, apply_func, verbose = True):
	base_dir = os.path.abspath(root_dir)
	for root, subdirs, files in os.walk(base_dir):
		if verbose:
			print('# Directory: ' + root)
		for filename in files:
			if os.path.splitext(filename)[1] == extension:
				if verbose:
					print('  - %s ' % (filename))
				file_path = os.path.join(root, filename)
				res = apply_func(file_path)
    
printMidiFileStatistics('/content/')